{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%pip install kagglehub\n",
    "%pip install pandas\n",
    "%pip install -U jupyter ipywidgets\n",
    "%pip install -U jupyterlab-widgets\n",
    "%pip install seaborn\n",
    "%pip install scikit-learn\n",
    "%pip install gensim\n",
    "%pip install numpy==1.26.4"
   ],
   "id": "9305ec86cbc56930"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "file_path = \"arxiv.csv\"  # File in locale poiché convertito localmente da JSON a csv\n",
    "\n",
    "# Carica il file CSV in un DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Stampa il numero di righe e mostra le prime righe\n",
    "print(f\"Numero di righe nel dataset: {df.shape[0]}\")\n",
    "df.head()"
   ],
   "id": "9cf309f44c1e2f53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# df = df.sample(n=10000, random_state=42)\n",
    "\n",
    "df1 = df.drop(columns=['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'update_date'])\n",
    "\n",
    "df1.head()"
   ],
   "id": "48c5b4b714f0db46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df1 = df1[df1['categories'].apply(lambda x: isinstance(x, str) and ',' not in x and ' ' not in x)]\n",
    "print(f\"Numero di righe nel dataset: {df1.shape[0]}\")\n",
    "df1.head()"
   ],
   "id": "21db79b41e15d146"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Rimuovere duplicati\n",
    "df1 = df1.drop_duplicates()\n",
    "\n",
    "# Verificare e gestire dati mancanti\n",
    "df1 = df1.dropna().reset_index(drop=True)  # Rimuove righe con valori NaN\n",
    "\n",
    "print(f\"Numero di righe nel dataset dopo la pulizia: {df1.shape[0]}\")\n",
    "\n",
    "df1.head()"
   ],
   "id": "c60ff47c99de61ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def clean_text(text):\n",
    "    # Rimuove link, caratteri speciali e converte in minuscolo\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)  # Rimuove menzioni e hashtag\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", '', text)  # Mantiene solo lettere e numeri\n",
    "    text = text.lower()  # Converte in minuscolo\n",
    "    text = text.strip()  # Rimuove spazi extra\n",
    "    return text\n",
    "\n",
    "# Applicare la pulizia\n",
    "df1['abstract'] = df1['abstract'].apply(clean_text)\n",
    "\n",
    "df1.head()"
   ],
   "id": "8c5b3f18bcc34a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Controlla la distribuzione delle etichette\n",
    "label_counts = df1['categories'].value_counts()\n",
    "\n",
    "# Stampa i conteggi\n",
    "print(label_counts)\n",
    "\n",
    "# Visualizza la distribuzione\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values)\n",
    "plt.title(\"Distribuzione delle etichette\")\n",
    "plt.xlabel(\"Etichette\")\n",
    "plt.ylabel(\"Conteggio\")\n",
    "plt.show()"
   ],
   "id": "34675032a0f7e823"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Definisci le 5 categorie principali su cui concentrarti\n",
    "top_4_categories = ['astro-ph', 'hep-ph', 'quant-ph', 'cs.CV']\n",
    "\n",
    "# Filtra il dataset per mantenere solo le righe con le categorie principali\n",
    "df1 = df1[df1['categories'].isin(top_4_categories)]\n",
    "\n",
    "df1.reset_index(drop=True)\n",
    "\n",
    "print(f\"Numero di righe nel dataset dopo la pulizia: {df1.shape[0]}\")\n",
    "\n",
    "df1.head()"
   ],
   "id": "c08238d3d2866fbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Controlla la distribuzione delle etichette\n",
    "label_counts = df1['categories'].value_counts()\n",
    "\n",
    "# Stampa i conteggi\n",
    "print(label_counts)\n",
    "\n",
    "# Visualizza la distribuzione\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=label_counts.index, y=label_counts.values)\n",
    "plt.title(\"Distribuzione delle etichette\")\n",
    "plt.xlabel(\"Etichette\")\n",
    "plt.ylabel(\"Conteggio\")\n",
    "plt.show()"
   ],
   "id": "e511c0d42fe37be9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Undersampling: trovare la dimensione della classe minoritaria\n",
    "min_class_size = label_counts.min()\n",
    "\n",
    "# Creare un nuovo dataset con undersampling\n",
    "undersampled_data = df1.groupby('categories').sample(n=min_class_size, random_state=42)\n",
    "\n",
    "# Verificare la nuova distribuzione delle etichette\n",
    "undersampled_label_counts = undersampled_data['categories'].value_counts()\n",
    "\n",
    "print(undersampled_label_counts)\n",
    "\n",
    "# Visualizzare la nuova distribuzione delle etichette\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=undersampled_label_counts.index, y=undersampled_label_counts.values)\n",
    "plt.title(\"Distribuzione delle etichette dopo undersampling\")\n",
    "plt.xlabel(\"Etichette\")\n",
    "plt.ylabel(\"Conteggio\")\n",
    "plt.show()"
   ],
   "id": "e8b27ff7ff8732a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Pulizia dei testi\n",
    "abstract = undersampled_data['abstract']\n",
    "\n",
    "# Contare le parole in ogni testo\n",
    "word_counts = abstract.apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Calcolare il massimo numero di parole e il testo corrispondente\n",
    "max_word_count = word_counts.max()\n",
    "\n",
    "# Assicurarsi che l'indice massimo sia un intero e ottenere il testo corrispondente\n",
    "max_word_index = word_counts.idxmax()\n",
    "max_word_text = abstract.loc[max_word_index]\n",
    "\n",
    "# Calcolare la media delle parole\n",
    "mean_word_count = word_counts.mean()\n",
    "\n",
    "# Stampare i risultati\n",
    "print(f\"Massimo numero di parole: {max_word_count}\")\n",
    "print(f\"Testo con più parole: {max_word_text}\")\n",
    "print(f\"Media del numero di parole: {mean_word_count:.2f}\")"
   ],
   "id": "57702472c3e62e96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Classificazione",
   "id": "78166063ef8bf9aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Caricamento del dataset generale\n",
    "X = undersampled_data['abstract']        # Colonna dei testi\n",
    "y = undersampled_data['categories']      # Colonna delle label\n",
    "\n",
    "# Step 1: Divisione del dataset generale in training e test set (70%-30%)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Step 2: Divisione del training set in training (85%) e validation set (15%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.15, random_state=42, stratify=y_train_full)\n",
    "\n",
    "# Verifica delle dimensioni\n",
    "print(\"Dimensioni del dataset:\")\n",
    "print(f\"Training set: {len(X_train)}\")\n",
    "print(f\"Validation set: {len(X_val)}\")\n",
    "print(f\"Test set: {len(X_test)}\")"
   ],
   "id": "360bcabcec1254bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Trasformazione in vettori di feature",
   "id": "3b30090d33df2546"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcolo della frequenza delle parole\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_counts = vectorizer.fit_transform(X_train)  # Usa il nuovo training set\n",
    "\n",
    "# Ordinare le parole per frequenza\n",
    "word_freq = dict(zip(vectorizer.get_feature_names_out(), X_counts.sum(axis=0).A1))\n",
    "sorted_word_freq = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Plot della distribuzione delle parole più frequenti\n",
    "top_words = 1000  # Analizza le prime 1000 parole\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, top_words + 1), [freq for _, freq in sorted_word_freq[:top_words]])\n",
    "plt.xlabel('Rango della parola')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.title('Distribuzione della frequenza delle parole nel training set')\n",
    "plt.show()"
   ],
   "id": "efce7784a0891d3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Il grafico è stato realizzato per una scelta ottimale del parametro <tt>`max_features`</tt> da scegliere per la trasformazione in vettori di feature.\n",
    "Si nota la curva segue la distribuzione di Zipf, dove poche parole hanno una frequenza molto alta, mentre la maggior parte delle parole appare poche volte.\n",
    "\n",
    "Intorno alle 150-200 parole si osserva un brusco calo della frequenza ed oltre le 500 parole, la frequenza diventa molto bassa.\n",
    "\n",
    "Dunque, per la scelta di max_features si hanno due strade:\n",
    "- valore pari a 500-1000 basandosi sulla curva;\n",
    "- valore tra 3000-5000 per catturare anche le code lunghe.\n",
    "\n",
    "I valori vanno testati empiricamente."
   ],
   "id": "93d37bded870e252"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TF-IDF",
   "id": "2b6f0349f6de6211"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "\n",
    "# Fit e trasformazione per il nuovo training, validation e test set\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)   # Nuovo training set\n",
    "X_val_tfidf = vectorizer.transform(X_val)          # Nuovo validation set\n",
    "X_test_tfidf = vectorizer.transform(X_test)        # Nuovo test set\n",
    "\n",
    "# Verifica delle dimensioni\n",
    "print(f\"Shape X_train_tfidf: {X_train_tfidf.shape}\")\n",
    "print(f\"Shape X_val_tfidf: {X_val_tfidf.shape}\")\n",
    "print(f\"Shape X_test_tfidf: {X_test_tfidf.shape}\")"
   ],
   "id": "ae446943eb0fc7d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Word2Vec",
   "id": "5725520ccd8a41a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "# Tokenizzazione dei testi\n",
    "X_train_tokens = [doc.split() for doc in X_train]  # Divide ogni documento in parole\n",
    "X_val_tokens = [doc.split() for doc in X_val]\n",
    "X_test_tokens = [doc.split() for doc in X_test]\n",
    "\n",
    "# Addestramento di Word2Vec sui dati di training\n",
    "word2vec_model = gensim.models.Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Funzione per calcolare la media delle embedding per ciascun documento\n",
    "def get_average_embedding(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "# Trasformazione dei set in embedding medie\n",
    "X_train_tfidf = np.array([get_average_embedding(tokens, word2vec_model) for tokens in X_train_tokens])\n",
    "X_val_tfidf = np.array([get_average_embedding(tokens, word2vec_model) for tokens in X_val_tokens])\n",
    "X_test_tfidf = np.array([get_average_embedding(tokens, word2vec_model) for tokens in X_test_tokens])\n",
    "\n",
    "# Verifica delle dimensioni\n",
    "print(f\"Shape X_train_w2v: {X_train_tfidf.shape}\")\n",
    "print(f\"Shape X_val_w2v: {X_val_tfidf.shape}\")\n",
    "print(f\"Shape X_test_w2v: {X_test_tfidf.shape}\")"
   ],
   "id": "52ed49eaffe8d676"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Naive Bayes",
   "id": "237b24d48fea6695"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Addestramento del modello Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)  # Usa il nuovo training set\n",
    "\n",
    "# Valutazione sul validation set\n",
    "y_pred_val_nb = nb_model.predict(X_val_tfidf)\n",
    "\n",
    "# Report delle metriche\n",
    "print(\"Naive Bayes Validation Accuracy:\", accuracy_score(y_val, y_pred_val_nb))\n",
    "print(\"Classification Report sul Validation Set:\\n\", classification_report(y_val, y_pred_val_nb))"
   ],
   "id": "5cf3c66fd8c00474"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Test set - Naive Bayes",
   "id": "60221aee2ca0f4c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Valutazione sul test set\n",
    "y_pred_test = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calcolo della accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Naive Bayes Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Report dettagliato di classificazione\n",
    "print(\"Test Set Classification Report:\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Calcolo della matrice di confusione\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Visualizzazione con Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=nb_model.classes_, yticklabels=nb_model.classes_)\n",
    "plt.title(\"Confusion Matrix - Naive Bayes\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n"
   ],
   "id": "2c52edbd12beda1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Curva ROC",
   "id": "8edba968fda0f875"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Binarizzare le etichette (necessario per calcolare la curva ROC)\n",
    "classes = nb_model.classes_\n",
    "y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "y_pred_proba = nb_model.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Calcolo della curva ROC per ciascuna classe\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, class_label in enumerate(classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_pred_proba[:, i])\n",
    "    auc_score = roc_auc_score(y_test_binarized[:, i], y_pred_proba[:, i])\n",
    "    plt.plot(fpr, tpr, label=f\"Class {class_label} (AUC = {auc_score:.2f})\")\n",
    "\n",
    "# Linea di riferimento\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "# Etichette e legenda\n",
    "plt.title(\"ROC Curve - Naive Bayes\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "e7688b010e568463"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Logistic Regression",
   "id": "5f3d62675b9e51f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Addestramento del modello Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_tfidf, y_train)  # Usa il nuovo training set\n",
    "\n",
    "# Valutazione sul validation set\n",
    "y_pred_val_lr = lr_model.predict(X_val_tfidf)\n",
    "\n",
    "# Report delle metriche\n",
    "print(\"Logistic Regression Validation Accuracy:\", accuracy_score(y_val, y_pred_val_lr))\n",
    "print(\"Classification Report sul Validation Set:\\n\", classification_report(y_val, y_pred_val_lr))"
   ],
   "id": "83cee3c051f9f9d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Test Set - Logistic Regression",
   "id": "2c46814ce264850e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Valutazione sul test set\n",
    "y_pred_test_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calcolo della accuracy\n",
    "test_accuracy_lr = accuracy_score(y_test, y_pred_test_lr)\n",
    "print(\"Logistic Regression Test Accuracy:\", test_accuracy_lr)\n",
    "\n",
    "# Report dettagliato di classificazione\n",
    "print(\"Test Set Classification Report:\\n\", classification_report(y_test, y_pred_test_lr))\n",
    "\n",
    "# Calcolo della matrice di confusione\n",
    "conf_matrix_lr = confusion_matrix(y_test, y_pred_test_lr)\n",
    "\n",
    "# Visualizzazione con Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_lr, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=lr_model.classes_, yticklabels=lr_model.classes_)\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ],
   "id": "d5a5e16350d190b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Curva ROC",
   "id": "1352ce770e8ea977"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Binarizzare le etichette (necessario per calcolare la curva ROC)\n",
    "classes = lr_model.classes_  # Modifica per Logistic Regression\n",
    "y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_tfidf)  # Predizione delle probabilità\n",
    "\n",
    "# Calcolo della curva ROC per ciascuna classe\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, class_label in enumerate(classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_pred_proba_lr[:, i])\n",
    "    auc_score = roc_auc_score(y_test_binarized[:, i], y_pred_proba_lr[:, i])\n",
    "    plt.plot(fpr, tpr, label=f\"Class {class_label} (AUC = {auc_score:.2f})\")\n",
    "\n",
    "# Linea di riferimento\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "# Etichette e legenda\n",
    "plt.title(\"ROC Curve - Logistic Regression\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "68a1a6bc3fd03f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Support Vector Machine (SVM)",
   "id": "b5979909accd173d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Per verificare la separabilità dei dati del dataset originale, poiché le feature sono categoriche, si deve utilizzare un Encoder per renderle numeriche.",
   "id": "cd1f28432bdcc102"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Assicurarsi che X sia un DataFrame\n",
    "if isinstance(X, pd.Series):\n",
    "    X = X.to_frame()  # Convertire la Series in DataFrame\n",
    "\n",
    "# Encoding di ogni colonna categorica\n",
    "label_encoders = {}\n",
    "for col in X.columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    label_encoders[col] = le"
   ],
   "id": "c53150b0e9345afa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assicurati che X sia un DataFrame con tutte le feature numeriche\n",
    "linear_check_df = X.copy()  # Prendi tutte le colonne di X\n",
    "linear_check_df['categories'] = y  # Aggiungi la colonna target\n",
    "\n",
    "# Pair plot delle feature colorate per classe\n",
    "sns.pairplot(linear_check_df, hue=\"categories\", diag_kind=\"kde\", markers=[\"o\", \"s\"])\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.suptitle(\"Pair Plot - Linear Separability Check\", y=1.02)\n",
    "plt.show()"
   ],
   "id": "4e103b90060d3c5c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Possiamo cercare di rappresentare i dati del dataset trasformato con TF-IDF in 2D tramite la TSNE, ma poiché TF-IDF lavora ad alta dimensionalità (circa 1000), la raffigurazione in 2D ottenuta con la TSNE potrebbe non essere accurata.",
   "id": "e0d13abfc5bb2d1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# t-SNE: Riduzione dimensionale a 2D\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, learning_rate=200)\n",
    "X_train_tsne = tsne.fit_transform(X_train_tfidf.toarray())  # Converti in array denso per t-SNE\n",
    "\n",
    "# Creare un DataFrame per la visualizzazione\n",
    "tsne_df = pd.DataFrame(X_train_tsne, columns=[\"TSNE1\", \"TSNE2\"])\n",
    "tsne_df['categories'] = y_train.reset_index(drop=True)  # Aggiungi la colonna target\n",
    "\n",
    "# Visualizzazione dei risultati t-SNE\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=tsne_df, x=\"TSNE1\", y=\"TSNE2\", hue=\"categories\", palette=\"Set1\", alpha=0.7)\n",
    "plt.title(\"Proiezione t-SNE delle Feature TF-IDF - Verifica Separabilità Lineare\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.legend(title=\"Categories\")\n",
    "plt.show()"
   ],
   "id": "4eaa0cec03723e6f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Anche se i punti non sono separabili in 2D, possono esserlo in uno spazio di 1000 dimensioni dove le feature TF-IDF hanno un'importanza diversa.",
   "id": "166e7c5909e5db19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Se si usa Word2Vec:",
   "id": "63ddc12256f3cf76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# t-SNE: Riduzione dimensionale a 2D\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, learning_rate=200)\n",
    "X_train_tsne = tsne.fit_transform(X_train_tfidf)  # Non serve .toarray()\n",
    "\n",
    "# Creare un DataFrame per la visualizzazione\n",
    "tsne_df = pd.DataFrame(X_train_tsne, columns=[\"TSNE1\", \"TSNE2\"])\n",
    "tsne_df['categories'] = y_train.reset_index(drop=True)  # Aggiungi la colonna target\n",
    "\n",
    "# Visualizzazione dei risultati t-SNE\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=tsne_df, x=\"TSNE1\", y=\"TSNE2\", hue=\"categories\", palette=\"Set1\", alpha=0.7)\n",
    "plt.title(\"Proiezione t-SNE delle Feature Word2Vec - Verifica Separabilità Lineare\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.legend(title=\"Categories\")\n",
    "plt.show()"
   ],
   "id": "fddb4c53d9300624"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Addestramento del modello SVM\n",
    "svm_model = LinearSVC(max_iter=1000, random_state=42)\n",
    "svm_model.fit(X_train_tfidf, y_train)  # Usa il nuovo training set\n",
    "\n",
    "# Valutazione sul validation set\n",
    "y_pred_val_svm = svm_model.predict(X_val_tfidf)\n",
    "\n",
    "# Report delle metriche\n",
    "print(\"SVM Validation Accuracy:\", accuracy_score(y_val, y_pred_val_svm))\n",
    "print(\"Classification Report sul Validation Set:\\n\", classification_report(y_val, y_pred_val_svm))"
   ],
   "id": "efb26a1206619f7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Test Set - Linear SVM",
   "id": "8c6c942002a5bfbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Valutazione sul test set\n",
    "y_pred_test_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calcolo della accuracy\n",
    "test_accuracy_svm = accuracy_score(y_test, y_pred_test_svm)\n",
    "print(\"Linear SVM Test Accuracy:\", test_accuracy_svm)\n",
    "\n",
    "# Report dettagliato di classificazione\n",
    "print(\"Test Set Classification Report:\\n\", classification_report(y_test, y_pred_test_svm))\n",
    "\n",
    "# Calcolo della matrice di confusione\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_test_svm)\n",
    "\n",
    "# Visualizzazione con Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_svm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=svm_model.classes_, yticklabels=svm_model.classes_)\n",
    "plt.title(\"Confusion Matrix - Linear SVM\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ],
   "id": "eaa958ced3168edc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Curva ROC",
   "id": "987a8ea9185aaf25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Addestrare SVC con kernel lineare e abilitare le probabilità\n",
    "svm_model_proba = SVC(kernel=\"linear\", probability=True, random_state=42)\n",
    "svm_model_proba.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Binarizzare le etichette (necessario per la curva ROC)\n",
    "classes = svm_model_proba.classes_  # Classi del modello\n",
    "y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# Predizione delle probabilità\n",
    "y_pred_proba_svm = svm_model_proba.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Calcolo della curva ROC per ciascuna classe\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, class_label in enumerate(classes):\n",
    "    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_pred_proba_svm[:, i])\n",
    "    auc_score = roc_auc_score(y_test_binarized[:, i], y_pred_proba_svm[:, i])\n",
    "    plt.plot(fpr, tpr, label=f\"Class {class_label} (AUC = {auc_score:.2f})\")\n",
    "\n",
    "# Linea di riferimento\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "# Etichette e legenda\n",
    "plt.title(\"ROC Curve - Linear SVM\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "18ce81d1e5cff598"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
